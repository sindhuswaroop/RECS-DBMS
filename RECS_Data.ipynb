{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading RECS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read RECS data file\n",
    "\n",
    "recs_data = pd.read_csv(\"recs2020_public_v7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOEID</th>\n",
       "      <th>REGIONC</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>state_postal</th>\n",
       "      <th>state_name</th>\n",
       "      <th>BA_climate</th>\n",
       "      <th>IECC_climate_code</th>\n",
       "      <th>UATYP10</th>\n",
       "      <th>HDD65</th>\n",
       "      <th>...</th>\n",
       "      <th>EVCHRGHOME</th>\n",
       "      <th>EVCHRGAPT</th>\n",
       "      <th>EVCHRGWKS</th>\n",
       "      <th>EVCHRGBUS</th>\n",
       "      <th>EVCHRGMUNI</th>\n",
       "      <th>EVCHRGDLR</th>\n",
       "      <th>EVCHRGHWY</th>\n",
       "      <th>EVCHRGOTH</th>\n",
       "      <th>EVHOMEAMT</th>\n",
       "      <th>EVCHRGTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>WEST</td>\n",
       "      <td>Mountain South</td>\n",
       "      <td>35</td>\n",
       "      <td>NM</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Mixed-Dry</td>\n",
       "      <td>4B</td>\n",
       "      <td>U</td>\n",
       "      <td>3844</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>5</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Mixed-Humid</td>\n",
       "      <td>4A</td>\n",
       "      <td>U</td>\n",
       "      <td>3766</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>WEST</td>\n",
       "      <td>Mountain South</td>\n",
       "      <td>35</td>\n",
       "      <td>NM</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Mixed-Dry</td>\n",
       "      <td>4B</td>\n",
       "      <td>U</td>\n",
       "      <td>3819</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>45</td>\n",
       "      <td>SC</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Mixed-Humid</td>\n",
       "      <td>3A</td>\n",
       "      <td>U</td>\n",
       "      <td>2614</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>NORTHEAST</td>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>34</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Mixed-Humid</td>\n",
       "      <td>4A</td>\n",
       "      <td>U</td>\n",
       "      <td>4219</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 799 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DOEID    REGIONC            DIVISION  STATE_FIPS state_postal  \\\n",
       "0  100001       WEST      Mountain South          35           NM   \n",
       "1  100002      SOUTH  West South Central           5           AR   \n",
       "2  100003       WEST      Mountain South          35           NM   \n",
       "3  100004      SOUTH      South Atlantic          45           SC   \n",
       "4  100005  NORTHEAST     Middle Atlantic          34           NJ   \n",
       "\n",
       "       state_name   BA_climate IECC_climate_code UATYP10  HDD65  ...  \\\n",
       "0      New Mexico    Mixed-Dry                4B       U   3844  ...   \n",
       "1        Arkansas  Mixed-Humid                4A       U   3766  ...   \n",
       "2      New Mexico    Mixed-Dry                4B       U   3819  ...   \n",
       "3  South Carolina  Mixed-Humid                3A       U   2614  ...   \n",
       "4      New Jersey  Mixed-Humid                4A       U   4219  ...   \n",
       "\n",
       "   EVCHRGHOME  EVCHRGAPT  EVCHRGWKS  EVCHRGBUS  EVCHRGMUNI  EVCHRGDLR  \\\n",
       "0        -2.0         -2       -2.0       -2.0        -2.0       -2.0   \n",
       "1        -2.0         -2       -2.0       -2.0        -2.0       -2.0   \n",
       "2        -2.0         -2       -2.0       -2.0        -2.0       -2.0   \n",
       "3        -2.0         -2       -2.0       -2.0        -2.0       -2.0   \n",
       "4        -2.0         -2       -2.0       -2.0        -2.0       -2.0   \n",
       "\n",
       "   EVCHRGHWY  EVCHRGOTH  EVHOMEAMT  EVCHRGTYPE  \n",
       "0       -2.0       -2.0       -2.0        -2.0  \n",
       "1       -2.0       -2.0       -2.0        -2.0  \n",
       "2       -2.0       -2.0       -2.0        -2.0  \n",
       "3       -2.0       -2.0       -2.0        -2.0  \n",
       "4       -2.0       -2.0       -2.0        -2.0  \n",
       "\n",
       "[5 rows x 799 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " DOEID            0\n",
      "REGIONC          0\n",
      "DIVISION         0\n",
      "STATE_FIPS       0\n",
      "state_postal     0\n",
      "                ..\n",
      "EVCHRGDLR       75\n",
      "EVCHRGHWY       72\n",
      "EVCHRGOTH       64\n",
      "EVHOMEAMT       10\n",
      "EVCHRGTYPE       9\n",
      "Length: 799, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validation Check 1: Checking for duplicated records and missing values\n",
    "\n",
    "# Duplicate records check\n",
    "duplicate_records = recs_data.duplicated().sum()\n",
    "assert duplicate_records == 0, f\"Dataset contains {duplicate_records} duplicate records\"\n",
    "recs_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Missing values check\n",
    "missing_values = recs_data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "recs_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Check 2: Checking for outliers in Heating Degree Days\n",
    "\n",
    "assert recs_data['HDD30YR_PUB'].between(0, 16071).all(), \"HDD30YR_PUB values should be between 0 and 16071\"\n",
    "recs_data=recs_data[(recs_data['HDD30YR_PUB']>=0) & (recs_data['HDD30YR_PUB']<=16071)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Check 3: Checking for geographical consistency\n",
    "\n",
    "valid_states = {\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "                \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \n",
    "                \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"}\n",
    "assert set(recs_data['state_postal'].unique()).issubset(valid_states), \"Invalid states found in the dataset\"\n",
    "recs_data = recs_data[recs_data['state_postal'].isin(valid_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Check 4: Checking data types\n",
    "\n",
    "def check_dtypes(recs_data, variable_name, datatype):\n",
    "    assert recs_data[variable_name].dtypes == datatype, f\"{variable_name} should be an integer\"\n",
    "    recs_data[variable_name].astype(datatype).dtypes\n",
    "    return recs_data\n",
    "\n",
    "recs_data = check_dtypes(recs_data, 'TYPEHUQ', 'int64')\n",
    "recs_data = check_dtypes(recs_data, 'WALLTYPE', 'int64')\n",
    "recs_data = check_dtypes(recs_data, 'ACEQUIPM_PUB', 'int64')\n",
    "recs_data = check_dtypes(recs_data, 'FUELHEAT', 'int64')\n",
    "recs_data = check_dtypes(recs_data, 'HDD30YR_PUB', 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Check 5: Checking for incorrect categorical values\n",
    "\n",
    "def check_values(recs_data, variable_name, valid_values):\n",
    "    assert set(recs_data[variable_name].unique()).issubset(valid_values), f\"Invalid {variable_name} values found\"\n",
    "    recs_data = recs_data[(recs_data[variable_name].isin(valid_values))]\n",
    "    return recs_data\n",
    "\n",
    "recs_data = check_values(recs_data, 'TYPEHUQ', [1, 2, 3, 4, 5])\n",
    "recs_data = check_values(recs_data, 'WALLTYPE', [1, 2, 3, 4, 5, 6, 7, 99])\n",
    "recs_data = check_values(recs_data, 'ACEQUIPM_PUB', [1, -2, 3, 4, 5, 6,])\n",
    "recs_data = check_values(recs_data, 'FUELHEAT', [1, 2, 3, 5, 7, 99, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Data into Database by Creating Connection to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automate SQL code generation for creating RECS_DATA table\n",
    "\n",
    "dtypes_df = recs_data.dtypes.to_frame('dtypes').reset_index()\n",
    "dtypes_df['dtypes'] = dtypes_df['dtypes'].replace('int64', 'INT')\n",
    "dtypes_df['dtypes'] = dtypes_df['dtypes'].replace('float64', 'FLOAT')\n",
    "dtypes_df['dtypes'] = dtypes_df['dtypes'].replace('object', 'VARCHAR(255)')\n",
    "dtypes_df['dtypes'] = dtypes_df['dtypes'].replace('O', 'VARCHAR(255)')\n",
    "\n",
    "dtypes_df['sql_cde'] = dtypes_df['index'] + ' ' + dtypes_df['dtypes'] + ', '\n",
    "\n",
    "col_names = ''\n",
    "\n",
    "for i in dtypes_df['sql_cde']:\n",
    "    col_names += i\n",
    "sql_create = f'CREATE OR REPLACE TABLE RECS_DB.RECS_DATA_SCHEMA.RECS_DATA ({col_names});'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data into RECS_DATA table\n",
    "\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "user=\"SindhuSwaroop\"\n",
    "role=\"accountadmin\"\n",
    "warehouse=\"compute_wh\"\n",
    "database=\"RECS_DB\"\n",
    "schema=\"recs_data_schema\"\n",
    "account = \"rhjhrje-st87781\"\n",
    "password = config_data.get(\"password\")\n",
    "\n",
    "conn=snowflake.connector.connect(user=user, \n",
    "                                 role=role, \n",
    "                                 warehouse=warehouse, \n",
    "                                 database=database, \n",
    "                                 schema=schema, \n",
    "                                 account=account, \n",
    "                                 password=password)\n",
    "\n",
    "engine = create_engine(\n",
    "    f'snowflake://{user}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'\n",
    ")\n",
    "\n",
    "recs_data.to_sql(name='recs_data', con=engine, if_exists='replace', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Codebook\n",
    "\n",
    "codes_data = pd.read_excel(\"RECS 2020 Codebook for Public File - v7.xlsx\", header=1, sheet_name='codebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Connection to Codes Schema in Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to codes_schema on Snowflake\n",
    "\n",
    "schema=\"codes_schema\"\n",
    "\n",
    "conn=snowflake.connector.connect(user=user, \n",
    "                                 role=role, \n",
    "                                 warehouse=warehouse, \n",
    "                                 database=database, \n",
    "                                 schema=schema, \n",
    "                                 account=account, \n",
    "                                 password=password)\n",
    "\n",
    "engine = create_engine(\n",
    "    f'snowflake://{user}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Type Tables for Required Variables and Ingesting Data into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/3619588838.py:19: UserWarning: The provided table name 'TYPE_HDD30YR_PUB' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  expanded_df.to_sql(name='TYPE_HDD30YR_PUB', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16072"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create type table for HDD30YR_PUB\n",
    "\n",
    "code_HDD30YR_PUB = codes_data[codes_data['Variable']==\"HDD30YR_PUB\"]\n",
    "\n",
    "# Expand the rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in code_HDD30YR_PUB.iterrows():\n",
    "    variable = row['Variable']\n",
    "    description = row['Description and Labels']\n",
    "    response_code_range = row['Response Codes']\n",
    "    \n",
    "    start, end = map(int, response_code_range.split('-'))\n",
    "    \n",
    "    for code in range(start, end + 1):\n",
    "        expanded_rows.append([variable, description, code])\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows, columns=['variable_name', 'description', 'code'])\n",
    "expanded_df.to_sql(name='TYPE_HDD30YR_PUB', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/4149091994.py:18: UserWarning: The provided table name 'TYPE_TYPEHUQ' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  expanded_df.to_sql(name='TYPE_TYPEHUQ', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create type table for TYPEHUQ\n",
    "\n",
    "code_TYPEHUQ = codes_data[codes_data['Variable']==\"TYPEHUQ\"]\n",
    "\n",
    "# Expand the rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in code_TYPEHUQ.iterrows():\n",
    "    variable = row['Variable']\n",
    "    description = row['Description and Labels']\n",
    "    response_codes = row['Response Codes'].split('\\n')\n",
    "    \n",
    "    for code_desc in response_codes:\n",
    "        code, desc = code_desc.split(' ', 1)\n",
    "        expanded_rows.append([variable, description, code, desc])\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows, columns=['variable_name', 'description', 'code', 'code_desc'])\n",
    "expanded_df.to_sql(name='TYPE_TYPEHUQ', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/1910766460.py:18: UserWarning: The provided table name 'TYPE_WALLTYPE' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  expanded_df.to_sql(name='TYPE_WALLTYPE', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create type table for WALLTYPE\n",
    "\n",
    "code_WALLTYPE = codes_data[codes_data['Variable']==\"WALLTYPE\"]\n",
    "\n",
    "# Expand the rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in code_WALLTYPE.iterrows():\n",
    "    variable = row['Variable']\n",
    "    description = row['Description and Labels']\n",
    "    response_codes = row['Response Codes'].split('\\n')\n",
    "    \n",
    "    for code_desc in response_codes:\n",
    "        code, desc = code_desc.split(' ', 1)\n",
    "        expanded_rows.append([variable, description, code, desc])\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows, columns=['variable_name', 'description', 'code', 'code_desc'])\n",
    "expanded_df.to_sql(name='TYPE_WALLTYPE', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/30216171.py:18: UserWarning: The provided table name 'TYPE_ACEQUIPM_PUB' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  expanded_df.to_sql(name='TYPE_ACEQUIPM_PUB', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create type table for ACEQUIPM_PUB\n",
    "\n",
    "code_ACEQUIPM_PUB = codes_data[codes_data['Variable']==\"ACEQUIPM_PUB\"]\n",
    "\n",
    "# Expand the rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in code_ACEQUIPM_PUB.iterrows():\n",
    "    variable = row['Variable']\n",
    "    description = row['Description and Labels']\n",
    "    response_codes = row['Response Codes'].split('\\n')\n",
    "    \n",
    "    for code_desc in response_codes:\n",
    "        code, desc = code_desc.split(' ', 1)\n",
    "        expanded_rows.append([variable, description, code, desc])\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows, columns=['variable_name', 'description', 'code', 'code_desc'])\n",
    "expanded_df.to_sql(name='TYPE_ACEQUIPM_PUB', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/660827295.py:18: UserWarning: The provided table name 'TYPE_FUELHEAT' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  expanded_df.to_sql(name='TYPE_FUELHEAT', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create type table for FUELHEAT\n",
    "\n",
    "code_FUELHEAT = codes_data[codes_data['Variable']==\"FUELHEAT\"]\n",
    "\n",
    "# Expand the rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in code_FUELHEAT.iterrows():\n",
    "    variable = row['Variable']\n",
    "    description = row['Description and Labels']\n",
    "    response_codes = row['Response Codes'].split('\\n')\n",
    "    \n",
    "    for code_desc in response_codes:\n",
    "        code, desc = code_desc.split(' ', 1)\n",
    "        expanded_rows.append([variable, description, code, desc])\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows, columns=['variable_name', 'description', 'code', 'code_desc'])\n",
    "expanded_df.to_sql(name='TYPE_FUELHEAT', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading State Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read State Dictionary\n",
    "\n",
    "state_data = pd.read_excel(\"RECS 2020 Codebook for Public File - v7.xlsx\", sheet_name='state_dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating States Table and Ingesting Data into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/zzp2wzs96_3b8mvqcqp1hbcw0000gn/T/ipykernel_19371/404408270.py:3: UserWarning: The provided table name 'STATES' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  state_data.to_sql(name='STATES', con=engine, if_exists='append', index=False, index_label=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create states table\n",
    "\n",
    "state_data.to_sql(name='STATES', con=engine, if_exists='append', index=False, index_label=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
